{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c0d79e9-09cc-4be9-9058-4e5fb6808321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Quick Titanic data prep (if you don't have it already)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b09380-b873-44bf-873a-69cce12a6b88",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe2a8c3-0c01-4695-ba50-f5bd128d22e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training data uploaded to: s3://sagemaker-us-east-2-854757836160/titanic-data/train/train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_880/2217492332.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].median(), inplace=True)\n",
      "/tmp/ipykernel_880/2217492332.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Initialize SageMaker session\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# Download Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Basic preprocessing\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "df['Embarked'] = df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "\n",
    "# Prepare for XGBoost (label first, then features)\n",
    "df_xgb = df[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "\n",
    "# Split and save\n",
    "train_data, test_data = train_test_split(df_xgb, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data.to_csv('train.csv', header=False, index=False)\n",
    "\n",
    "# Upload to S3\n",
    "train_path = f's3://{bucket}/titanic-data/train/train.csv'\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object('titanic-data/train/train.csv').upload_file('train.csv')\n",
    "\n",
    "print(f\"âœ… Training data uploaded to: {train_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f3b226-9f49-49d6-8549-9b9dd1b6d6cd",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29211f8f-f673-49e7-8319-8146d514ef73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2025-11-17-19-57-50-238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket: sagemaker-us-east-2-854757836160\n",
      "Using role: arn:aws:iam::854757836160:role/service-role/AmazonSageMaker-ExecutionRole-20251026T175451\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL A (Conservative)\n",
      "============================================================\n",
      "2025-11-17 19:57:52 Starting - Starting the training job...\n",
      "2025-11-17 19:58:25 Downloading - Downloading input data...\n",
      "2025-11-17 19:58:50 Downloading - Downloading the training image......\n",
      "2025-11-17 19:59:51 Training - Training image download completed. Training in progress.\n",
      "2025-11-17 19:59:51 Uploading - Uploading generated training model.\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34m[2025-11-17 19:59:47.040 ip-10-0-154-248.us-east-2.compute.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2025-11-17 19:59:47.062 ip-10-0-154-248.us-east-2.compute.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2025-11-17:19:59:47:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2025-11-17:19:59:47:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2025-11-17:19:59:47:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2025-11-17:19:59:47:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2025-11-17:19:59:47:INFO] Determined 0 GPU(s) available on the instance.\u001b[0m\n",
      "\u001b[34m[2025-11-17:19:59:47:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2025-11-17:19:59:47:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[2025-11-17:19:59:47:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2025-11-17:19:59:47:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2025-11-17:19:59:47:INFO] Train matrix has 712 rows and 7 columns\u001b[0m\n",
      "\u001b[34m[2025-11-17 19:59:47.439 ip-10-0-154-248.us-east-2.compute.internal:7 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2025-11-17 19:59:47.440 ip-10-0-154-248.us-east-2.compute.internal:7 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2025-11-17 19:59:47.440 ip-10-0-154-248.us-east-2.compute.internal:7 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2025-11-17 19:59:47.440 ip-10-0-154-248.us-east-2.compute.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2025-11-17:19:59:47:INFO] Debug hook created from config\u001b[0m\n",
      "\u001b[34m[19:59:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\u001b[0m\n",
      "\u001b[34m[0]#011train-logloss:0.56609\u001b[0m\n",
      "\u001b[34m[2025-11-17 19:59:47.452 ip-10-0-154-248.us-east-2.compute.internal:7 INFO hook.py:427] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2025-11-17 19:59:47.456 ip-10-0-154-248.us-east-2.compute.internal:7 INFO hook.py:491] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[1]#011train-logloss:0.49682\u001b[0m\n",
      "\u001b[34m[2]#011train-logloss:0.45271\u001b[0m\n",
      "\u001b[34m[3]#011train-logloss:0.42627\u001b[0m\n",
      "\u001b[34m[4]#011train-logloss:0.41011\u001b[0m\n",
      "\u001b[34m[5]#011train-logloss:0.39937\u001b[0m\n",
      "\u001b[34m[6]#011train-logloss:0.38988\u001b[0m\n",
      "\u001b[34m[7]#011train-logloss:0.38310\u001b[0m\n",
      "\u001b[34m[8]#011train-logloss:0.37640\u001b[0m\n",
      "\u001b[34m[9]#011train-logloss:0.37339\u001b[0m\n",
      "\u001b[34m[10]#011train-logloss:0.36840\u001b[0m\n",
      "\u001b[34m[11]#011train-logloss:0.36628\u001b[0m\n",
      "\u001b[34m[12]#011train-logloss:0.36294\u001b[0m\n",
      "\u001b[34m[13]#011train-logloss:0.35911\u001b[0m\n",
      "\u001b[34m[14]#011train-logloss:0.35708\u001b[0m\n",
      "\u001b[34m[15]#011train-logloss:0.35364\u001b[0m\n",
      "\u001b[34m[16]#011train-logloss:0.35256\u001b[0m\n",
      "\u001b[34m[17]#011train-logloss:0.34795\u001b[0m\n",
      "\u001b[34m[18]#011train-logloss:0.34653\u001b[0m\n",
      "\u001b[34m[19]#011train-logloss:0.34566\u001b[0m\n",
      "\u001b[34m[20]#011train-logloss:0.34297\u001b[0m\n",
      "\u001b[34m[21]#011train-logloss:0.34132\u001b[0m\n",
      "\u001b[34m[22]#011train-logloss:0.34009\u001b[0m\n",
      "\u001b[34m[23]#011train-logloss:0.33719\u001b[0m\n",
      "\u001b[34m[24]#011train-logloss:0.33166\u001b[0m\n",
      "\u001b[34m[25]#011train-logloss:0.33062\u001b[0m\n",
      "\u001b[34m[26]#011train-logloss:0.32593\u001b[0m\n",
      "\u001b[34m[27]#011train-logloss:0.32516\u001b[0m\n",
      "\u001b[34m[28]#011train-logloss:0.32337\u001b[0m\n",
      "\u001b[34m[29]#011train-logloss:0.32098\u001b[0m\n",
      "\u001b[34m[30]#011train-logloss:0.31720\u001b[0m\n",
      "\u001b[34m[31]#011train-logloss:0.31612\u001b[0m\n",
      "\u001b[34m[32]#011train-logloss:0.31342\u001b[0m\n",
      "\u001b[34m[33]#011train-logloss:0.31188\u001b[0m\n",
      "\u001b[34m[34]#011train-logloss:0.31084\u001b[0m\n",
      "\u001b[34m[35]#011train-logloss:0.30949\u001b[0m\n",
      "\u001b[34m[36]#011train-logloss:0.30815\u001b[0m\n",
      "\u001b[34m[37]#011train-logloss:0.30464\u001b[0m\n",
      "\u001b[34m[38]#011train-logloss:0.30404\u001b[0m\n",
      "\u001b[34m[39]#011train-logloss:0.30109\u001b[0m\n",
      "\u001b[34m[40]#011train-logloss:0.29933\u001b[0m\n",
      "\u001b[34m[41]#011train-logloss:0.29673\u001b[0m\n",
      "\u001b[34m[42]#011train-logloss:0.29579\u001b[0m\n",
      "\u001b[34m[43]#011train-logloss:0.29512\u001b[0m\n",
      "\u001b[34m[44]#011train-logloss:0.29480\u001b[0m\n",
      "\u001b[34m[45]#011train-logloss:0.29387\u001b[0m\n",
      "\u001b[34m[46]#011train-logloss:0.29311\u001b[0m\n",
      "\u001b[34m[47]#011train-logloss:0.29256\u001b[0m\n",
      "\u001b[34m[48]#011train-logloss:0.29176\u001b[0m\n",
      "\u001b[34m[49]#011train-logloss:0.28887\u001b[0m\n",
      "\n",
      "2025-11-17 20:00:04 Completed - Training job completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2025-11-17-20-00-37-185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 99\n",
      "Billable seconds: 99\n",
      "\n",
      "âœ… Model A trained successfully!\n",
      "Model A artifact: s3://sagemaker-us-east-2-854757836160/ab-test/model-a/sagemaker-xgboost-2025-11-17-19-57-50-238/output/model.tar.gz\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL B (Aggressive - Better Accuracy)\n",
      "============================================================\n",
      "2025-11-17 20:00:37 Starting - Starting the training job...\n",
      "2025-11-17 20:01:02 Starting - Preparing the instances for training...\n",
      "2025-11-17 20:01:19 Downloading - Downloading input data...\n",
      "2025-11-17 20:01:45 Downloading - Downloading the training image...\n",
      "2025-11-17 20:02:31 Training - Training image download completed. Training in progress..\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34m[2025-11-17 20:02:37.562 ip-10-0-78-198.us-east-2.compute.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2025-11-17 20:02:37.585 ip-10-0-78-198.us-east-2.compute.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2025-11-17:20:02:37:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2025-11-17:20:02:37:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2025-11-17:20:02:37:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2025-11-17:20:02:37:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2025-11-17:20:02:37:INFO] Determined 0 GPU(s) available on the instance.\u001b[0m\n",
      "\u001b[34m[2025-11-17:20:02:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2025-11-17:20:02:37:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[2025-11-17:20:02:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2025-11-17:20:02:37:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2025-11-17:20:02:37:INFO] Train matrix has 712 rows and 7 columns\u001b[0m\n",
      "\u001b[34m[2025-11-17 20:02:37.962 ip-10-0-78-198.us-east-2.compute.internal:7 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2025-11-17 20:02:37.962 ip-10-0-78-198.us-east-2.compute.internal:7 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2025-11-17 20:02:37.963 ip-10-0-78-198.us-east-2.compute.internal:7 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2025-11-17 20:02:37.963 ip-10-0-78-198.us-east-2.compute.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2025-11-17:20:02:37:INFO] Debug hook created from config\u001b[0m\n",
      "\u001b[34m[20:02:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\u001b[0m\n",
      "\u001b[34m[0]#011train-logloss:0.64263\u001b[0m\n",
      "\u001b[34m[2025-11-17 20:02:37.975 ip-10-0-78-198.us-east-2.compute.internal:7 INFO hook.py:427] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2025-11-17 20:02:37.978 ip-10-0-78-198.us-east-2.compute.internal:7 INFO hook.py:491] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[1]#011train-logloss:0.59896\u001b[0m\n",
      "\u001b[34m[2]#011train-logloss:0.56384\u001b[0m\n",
      "\u001b[34m[3]#011train-logloss:0.53235\u001b[0m\n",
      "\u001b[34m[4]#011train-logloss:0.50801\u001b[0m\n",
      "\u001b[34m[5]#011train-logloss:0.48507\u001b[0m\n",
      "\u001b[34m[6]#011train-logloss:0.46583\u001b[0m\n",
      "\u001b[34m[7]#011train-logloss:0.44857\u001b[0m\n",
      "\u001b[34m[8]#011train-logloss:0.43278\u001b[0m\n",
      "\u001b[34m[9]#011train-logloss:0.41903\u001b[0m\n",
      "\u001b[34m[10]#011train-logloss:0.40817\u001b[0m\n",
      "\u001b[34m[11]#011train-logloss:0.39859\u001b[0m\n",
      "\u001b[34m[12]#011train-logloss:0.38816\u001b[0m\n",
      "\u001b[34m[13]#011train-logloss:0.38063\u001b[0m\n",
      "\u001b[34m[14]#011train-logloss:0.37257\u001b[0m\n",
      "\u001b[34m[15]#011train-logloss:0.36530\u001b[0m\n",
      "\u001b[34m[16]#011train-logloss:0.35876\u001b[0m\n",
      "\u001b[34m[17]#011train-logloss:0.35268\u001b[0m\n",
      "\u001b[34m[18]#011train-logloss:0.34768\u001b[0m\n",
      "\u001b[34m[19]#011train-logloss:0.34206\u001b[0m\n",
      "\u001b[34m[20]#011train-logloss:0.33724\u001b[0m\n",
      "\u001b[34m[21]#011train-logloss:0.33223\u001b[0m\n",
      "\u001b[34m[22]#011train-logloss:0.32800\u001b[0m\n",
      "\u001b[34m[23]#011train-logloss:0.32348\u001b[0m\n",
      "\u001b[34m[24]#011train-logloss:0.31973\u001b[0m\n",
      "\u001b[34m[25]#011train-logloss:0.31691\u001b[0m\n",
      "\u001b[34m[26]#011train-logloss:0.31389\u001b[0m\n",
      "\u001b[34m[27]#011train-logloss:0.31002\u001b[0m\n",
      "\u001b[34m[28]#011train-logloss:0.30731\u001b[0m\n",
      "\u001b[34m[29]#011train-logloss:0.30313\u001b[0m\n",
      "\u001b[34m[30]#011train-logloss:0.29995\u001b[0m\n",
      "\u001b[34m[31]#011train-logloss:0.29753\u001b[0m\n",
      "\u001b[34m[32]#011train-logloss:0.29360\u001b[0m\n",
      "\u001b[34m[33]#011train-logloss:0.28995\u001b[0m\n",
      "\u001b[34m[34]#011train-logloss:0.28813\u001b[0m\n",
      "\u001b[34m[35]#011train-logloss:0.28507\u001b[0m\n",
      "\u001b[34m[36]#011train-logloss:0.28358\u001b[0m\n",
      "\u001b[34m[37]#011train-logloss:0.28153\u001b[0m\n",
      "\u001b[34m[38]#011train-logloss:0.27911\u001b[0m\n",
      "\u001b[34m[39]#011train-logloss:0.27592\u001b[0m\n",
      "\u001b[34m[40]#011train-logloss:0.27309\u001b[0m\n",
      "\u001b[34m[41]#011train-logloss:0.27124\u001b[0m\n",
      "\u001b[34m[42]#011train-logloss:0.26896\u001b[0m\n",
      "\u001b[34m[43]#011train-logloss:0.26792\u001b[0m\n",
      "\u001b[34m[44]#011train-logloss:0.26593\u001b[0m\n",
      "\u001b[34m[45]#011train-logloss:0.26446\u001b[0m\n",
      "\u001b[34m[46]#011train-logloss:0.26273\u001b[0m\n",
      "\u001b[34m[47]#011train-logloss:0.26057\u001b[0m\n",
      "\u001b[34m[48]#011train-logloss:0.25962\u001b[0m\n",
      "\u001b[34m[49]#011train-logloss:0.25876\u001b[0m\n",
      "\u001b[34m[50]#011train-logloss:0.25709\u001b[0m\n",
      "\u001b[34m[51]#011train-logloss:0.25471\u001b[0m\n",
      "\u001b[34m[52]#011train-logloss:0.25260\u001b[0m\n",
      "\u001b[34m[53]#011train-logloss:0.25119\u001b[0m\n",
      "\u001b[34m[54]#011train-logloss:0.24965\u001b[0m\n",
      "\u001b[34m[55]#011train-logloss:0.24809\u001b[0m\n",
      "\u001b[34m[56]#011train-logloss:0.24689\u001b[0m\n",
      "\u001b[34m[57]#011train-logloss:0.24403\u001b[0m\n",
      "\u001b[34m[58]#011train-logloss:0.24278\u001b[0m\n",
      "\u001b[34m[59]#011train-logloss:0.24080\u001b[0m\n",
      "\u001b[34m[60]#011train-logloss:0.23907\u001b[0m\n",
      "\u001b[34m[61]#011train-logloss:0.23759\u001b[0m\n",
      "\u001b[34m[62]#011train-logloss:0.23635\u001b[0m\n",
      "\u001b[34m[63]#011train-logloss:0.23452\u001b[0m\n",
      "\u001b[34m[64]#011train-logloss:0.23330\u001b[0m\n",
      "\u001b[34m[65]#011train-logloss:0.23130\u001b[0m\n",
      "\u001b[34m[66]#011train-logloss:0.22967\u001b[0m\n",
      "\u001b[34m[67]#011train-logloss:0.22871\u001b[0m\n",
      "\u001b[34m[68]#011train-logloss:0.22730\u001b[0m\n",
      "\u001b[34m[69]#011train-logloss:0.22576\u001b[0m\n",
      "\u001b[34m[70]#011train-logloss:0.22468\u001b[0m\n",
      "\u001b[34m[71]#011train-logloss:0.22348\u001b[0m\n",
      "\u001b[34m[72]#011train-logloss:0.22305\u001b[0m\n",
      "\u001b[34m[73]#011train-logloss:0.22185\u001b[0m\n",
      "\u001b[34m[74]#011train-logloss:0.22062\u001b[0m\n",
      "\u001b[34m[75]#011train-logloss:0.21922\u001b[0m\n",
      "\u001b[34m[76]#011train-logloss:0.21816\u001b[0m\n",
      "\u001b[34m[77]#011train-logloss:0.21664\u001b[0m\n",
      "\u001b[34m[78]#011train-logloss:0.21577\u001b[0m\n",
      "\u001b[34m[79]#011train-logloss:0.21461\u001b[0m\n",
      "\u001b[34m[80]#011train-logloss:0.21385\u001b[0m\n",
      "\u001b[34m[81]#011train-logloss:0.21247\u001b[0m\n",
      "\u001b[34m[82]#011train-logloss:0.21159\u001b[0m\n",
      "\u001b[34m[83]#011train-logloss:0.21079\u001b[0m\n",
      "\u001b[34m[84]#011train-logloss:0.20996\u001b[0m\n",
      "\u001b[34m[85]#011train-logloss:0.20870\u001b[0m\n",
      "\u001b[34m[86]#011train-logloss:0.20748\u001b[0m\n",
      "\u001b[34m[87]#011train-logloss:0.20655\u001b[0m\n",
      "\u001b[34m[88]#011train-logloss:0.20554\u001b[0m\n",
      "\u001b[34m[89]#011train-logloss:0.20464\u001b[0m\n",
      "\u001b[34m[90]#011train-logloss:0.20391\u001b[0m\n",
      "\u001b[34m[91]#011train-logloss:0.20300\u001b[0m\n",
      "\u001b[34m[92]#011train-logloss:0.20185\u001b[0m\n",
      "\u001b[34m[93]#011train-logloss:0.20141\u001b[0m\n",
      "\u001b[34m[94]#011train-logloss:0.20035\u001b[0m\n",
      "\u001b[34m[95]#011train-logloss:0.19945\u001b[0m\n",
      "\u001b[34m[96]#011train-logloss:0.19823\u001b[0m\n",
      "\u001b[34m[97]#011train-logloss:0.19736\u001b[0m\n",
      "\u001b[34m[98]#011train-logloss:0.19656\u001b[0m\n",
      "\u001b[34m[99]#011train-logloss:0.19625\u001b[0m\n",
      "\n",
      "2025-11-17 20:02:54 Uploading - Uploading generated training model\n",
      "2025-11-17 20:02:54 Completed - Training job completed\n",
      "Training seconds: 94\n",
      "Billable seconds: 94\n",
      "\n",
      "âœ… Model B trained successfully!\n",
      "Model B artifact: s3://sagemaker-us-east-2-854757836160/ab-test/model-b/sagemaker-xgboost-2025-11-17-20-00-37-185/output/model.tar.gz\n",
      "\n",
      "============================================================\n",
      "PHASE 1 COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Both models trained and saved to S3:\n",
      "  Model A: s3://sagemaker-us-east-2-854757836160/ab-test/model-a/sagemaker-xgboost-2025-11-17-19-57-50-238/output/model.tar.gz\n",
      "  Model B: s3://sagemaker-us-east-2-854757836160/ab-test/model-b/sagemaker-xgboost-2025-11-17-20-00-37-185/output/model.tar.gz\n",
      "\n",
      "Ready for Phase 2: Deployment!\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using bucket: {bucket}\")\n",
    "print(f\"Using role: {role}\")\n",
    "\n",
    "# Get XGBoost container\n",
    "container = image_uris.retrieve('xgboost', sess.boto_region_name, '1.5-1')\n",
    "\n",
    "# Path to your training data (assuming you have it from Week 2)\n",
    "train_path = f's3://{bucket}/titanic-data/train/'\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING MODEL A (Conservative)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Model A: Conservative hyperparameters\n",
    "xgb_model_a = Estimator(\n",
    "    image_uri=container,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    output_path=f's3://{bucket}/ab-test/model-a/',\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "# Conservative hyperparameters (faster, simpler)\n",
    "xgb_model_a.set_hyperparameters(\n",
    "    objective='binary:logistic',\n",
    "    num_round=50,         # Fewer rounds\n",
    "    max_depth=3,          # Shallower trees\n",
    "    eta=0.3,              # Higher learning rate\n",
    "    subsample=1.0         # Use all data\n",
    ")\n",
    "\n",
    "# Train Model A\n",
    "xgb_model_a.fit({'train': TrainingInput(train_path, content_type='text/csv')})\n",
    "\n",
    "print(f\"\\nâœ… Model A trained successfully!\")\n",
    "print(f\"Model A artifact: {xgb_model_a.model_data}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING MODEL B (Aggressive - Better Accuracy)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Model B: Aggressive hyperparameters\n",
    "xgb_model_b = Estimator(\n",
    "    image_uri=container,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    output_path=f's3://{bucket}/ab-test/model-b/',\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "# Aggressive hyperparameters (more accurate, slower)\n",
    "xgb_model_b.set_hyperparameters(\n",
    "    objective='binary:logistic',\n",
    "    num_round=100,        # More rounds\n",
    "    max_depth=6,          # Deeper trees\n",
    "    eta=0.1,              # Lower learning rate\n",
    "    subsample=0.8         # Use 80% of data per tree\n",
    ")\n",
    "\n",
    "# Train Model B\n",
    "xgb_model_b.fit({'train': TrainingInput(train_path, content_type='text/csv')})\n",
    "\n",
    "print(f\"\\nâœ… Model B trained successfully!\")\n",
    "print(f\"Model B artifact: {xgb_model_b.model_data}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 1 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nBoth models trained and saved to S3:\")\n",
    "print(f\"  Model A: {xgb_model_a.model_data}\")\n",
    "print(f\"  Model B: {xgb_model_b.model_data}\")\n",
    "print(\"\\nReady for Phase 2: Deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45224549-36d8-431f-8be8-eaae614627e9",
   "metadata": {},
   "source": [
    "## Multi-Variant Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbce6671-bf8e-462b-a73f-701c329d2bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PHASE 2: DEPLOY MULTI-VARIANT ENDPOINT\n",
      "============================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Checking for existing endpoints to clean up...\n",
      "------------------------------------------------------------\n",
      "Found existing endpoint: titanic-ab-test-20251117-200652\n",
      "  Deleting to free up resources...\n",
      "  âœ… Deleted\n",
      "\n",
      "Waiting 30 seconds for resources to be released...\n",
      "\n",
      "------------------------------------------------------------\n",
      "Creating Model A and Model B\n",
      "------------------------------------------------------------\n",
      "Creating Model A: model-a-20251117201745\n",
      "âœ… Model A created successfully\n",
      "Creating Model B: model-b-20251117201746\n",
      "âœ… Model B created successfully\n",
      "\n",
      "------------------------------------------------------------\n",
      "Deploying both models with 80/20 traffic split\n",
      "Using ml.t2.medium instances (within quota)\n",
      "------------------------------------------------------------\n",
      "Creating endpoint config: ab-config-20251117201747\n",
      "âœ… Endpoint config created\n",
      "\n",
      "Creating endpoint: titanic-ab-test-20251117-201747\n",
      "(This takes ~8-10 minutes...)\n",
      "Waiting for endpoint to be in service...\n",
      "\n",
      "âœ… Endpoint deployed successfully!\n",
      "\n",
      "============================================================\n",
      "PHASE 2 COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Endpoint: titanic-ab-test-20251117-201747\n",
      "Traffic split:\n",
      "  VariantA (Conservative): 80%\n",
      "  VariantB (Aggressive):   20%\n",
      "\n",
      "Both variants are now live and receiving traffic!\n",
      "\n",
      "ðŸ’¾ Save this endpoint name: titanic-ab-test-20251117-201747\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 2: DEPLOY MULTI-VARIANT ENDPOINT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get SageMaker client\n",
    "client = boto3.client('sagemaker')\n",
    "\n",
    "# ============================================================\n",
    "# First, check for and delete any existing endpoints\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Checking for existing endpoints to clean up...\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "try:\n",
    "    response = client.list_endpoints(\n",
    "        StatusEquals='InService',\n",
    "        MaxResults=100\n",
    "    )\n",
    "    \n",
    "    for endpoint in response['Endpoints']:\n",
    "        if 'titanic-ab-test' in endpoint['EndpointName']:\n",
    "            print(f\"Found existing endpoint: {endpoint['EndpointName']}\")\n",
    "            print(f\"  Deleting to free up resources...\")\n",
    "            client.delete_endpoint(EndpointName=endpoint['EndpointName'])\n",
    "            print(f\"  âœ… Deleted\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: {e}\")\n",
    "\n",
    "print(\"\\nWaiting 30 seconds for resources to be released...\")\n",
    "time.sleep(30)\n",
    "\n",
    "# ============================================================\n",
    "# Create and Register Both Models\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Creating Model A and Model B\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Create Model A\n",
    "model_a_name = f'model-a-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'\n",
    "print(f\"Creating Model A: {model_a_name}\")\n",
    "\n",
    "client.create_model(\n",
    "    ModelName=model_a_name,\n",
    "    PrimaryContainer={\n",
    "        'Image': container,\n",
    "        'ModelDataUrl': xgb_model_a.model_data\n",
    "    },\n",
    "    ExecutionRoleArn=role\n",
    ")\n",
    "print(\"âœ… Model A created successfully\")\n",
    "\n",
    "# Create Model B\n",
    "model_b_name = f'model-b-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'\n",
    "print(f\"Creating Model B: {model_b_name}\")\n",
    "\n",
    "client.create_model(\n",
    "    ModelName=model_b_name,\n",
    "    PrimaryContainer={\n",
    "        'Image': container,\n",
    "        'ModelDataUrl': xgb_model_b.model_data\n",
    "    },\n",
    "    ExecutionRoleArn=role\n",
    ")\n",
    "print(\"âœ… Model B created successfully\")\n",
    "\n",
    "# ============================================================\n",
    "# Deploy Both Models with Traffic Split (using ml.t2.medium)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Deploying both models with 80/20 traffic split\")\n",
    "print(\"Using ml.t2.medium instances (within quota)\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Create endpoint configuration\n",
    "endpoint_config_name = f'ab-config-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'\n",
    "endpoint_name = f'titanic-ab-test-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "\n",
    "print(f\"Creating endpoint config: {endpoint_config_name}\")\n",
    "\n",
    "client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'VariantA',\n",
    "            'ModelName': model_a_name,\n",
    "            'InitialInstanceCount': 1,\n",
    "            'InstanceType': 'ml.t2.medium',  # Smaller instance\n",
    "            'InitialVariantWeight': 80\n",
    "        },\n",
    "        {\n",
    "            'VariantName': 'VariantB',\n",
    "            'ModelName': model_b_name,\n",
    "            'InitialInstanceCount': 1,\n",
    "            'InstanceType': 'ml.t2.medium',  # Smaller instance\n",
    "            'InitialVariantWeight': 20\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(\"âœ… Endpoint config created\")\n",
    "\n",
    "# Create endpoint\n",
    "print(f\"\\nCreating endpoint: {endpoint_name}\")\n",
    "print(\"(This takes ~8-10 minutes...)\")\n",
    "\n",
    "client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "# Wait for endpoint to be in service\n",
    "print(\"Waiting for endpoint to be in service...\")\n",
    "waiter = client.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "\n",
    "print(f\"\\nâœ… Endpoint deployed successfully!\")\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 2 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nEndpoint: {endpoint_name}\")\n",
    "print(f\"Traffic split:\")\n",
    "print(f\"  VariantA (Conservative): 80%\")\n",
    "print(f\"  VariantB (Aggressive):   20%\")\n",
    "print(f\"\\nBoth variants are now live and receiving traffic!\")\n",
    "\n",
    "# Create predictor for Phase 3\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=CSVSerializer()\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ’¾ Save this endpoint name: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ea98b-9450-469b-8e7b-0e68cfa67eb0",
   "metadata": {},
   "source": [
    "## Testing the Traffic Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e89100a9-a009-41cb-8c2d-9c5539074ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PHASE 3: TEST TRAFFIC SPLIT\n",
      "============================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 1: Sending 100 test predictions\n",
      "------------------------------------------------------------\n",
      "\n",
      "Sending predictions and tracking variants...\n",
      "(This will take ~30 seconds)\n",
      "\n",
      "  Sent 20/100 predictions...\n",
      "  Sent 40/100 predictions...\n",
      "  Sent 60/100 predictions...\n",
      "  Sent 80/100 predictions...\n",
      "  Sent 100/100 predictions...\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 2: Traffic Distribution Analysis\n",
      "------------------------------------------------------------\n",
      "\n",
      "Results from 100 predictions:\n",
      "  VariantA (Conservative): 86 requests (86%)\n",
      "  VariantB (Aggressive):   14 requests (14%)\n",
      "\n",
      "Expected distribution:\n",
      "  VariantA: 80%\n",
      "  VariantB: 20%\n",
      "\n",
      "âœ… Traffic split is working correctly!\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 3: Testing Variant Targeting\n",
      "------------------------------------------------------------\n",
      "\n",
      "Sending prediction to VariantA specifically:\n",
      "  Variant: VariantA\n",
      "  Prediction: 0.14891666173934937\n",
      "\n",
      "\n",
      "Sending prediction to VariantB specifically:\n",
      "  Variant: VariantB\n",
      "  Prediction: 0.09227834641933441\n",
      "\n",
      "\n",
      "âœ… Both variants are responding correctly!\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 4: Endpoint Status Check\n",
      "------------------------------------------------------------\n",
      "\n",
      "Endpoint: titanic-ab-test-20251117-201747\n",
      "Status: InService\n",
      "\n",
      "Production Variants:\n",
      "\n",
      "  VariantA:\n",
      "    Current Weight: 80.0\n",
      "    Desired Weight: 80.0\n",
      "    Current Instance Count: 1\n",
      "\n",
      "  VariantB:\n",
      "    Current Weight: 20.0\n",
      "    Desired Weight: 20.0\n",
      "    Current Instance Count: 1\n",
      "\n",
      "============================================================\n",
      "PHASE 3 COMPLETE!\n",
      "============================================================\n",
      "\n",
      "âœ… Traffic split verified and working!\n",
      "âœ… Both variants tested successfully!\n",
      "\n",
      "Ready for Phase 4: Monitoring metrics in CloudWatch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 3: TEST TRAFFIC SPLIT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================\n",
    "# STEP 1: Send test predictions and track which variant responds\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"STEP 1: Sending 100 test predictions\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Sample test data (passenger features)\n",
    "# Format: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked\n",
    "test_samples = [\n",
    "    '3,0,22,1,0,7.25,0',      # Young male, 3rd class\n",
    "    '1,1,38,1,0,71.28,1',     # Female, 1st class\n",
    "    '3,1,26,0,0,7.92,0',      # Young female, 3rd class\n",
    "    '1,0,35,1,0,53.10,0',     # Male, 1st class\n",
    "    '3,0,35,0,0,8.05,0',      # Male, 3rd class\n",
    "]\n",
    "\n",
    "# Send predictions and track variants\n",
    "variant_counts = []\n",
    "\n",
    "print(\"\\nSending predictions and tracking variants...\")\n",
    "print(\"(This will take ~30 seconds)\\n\")\n",
    "\n",
    "runtime_client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "for i in range(100):\n",
    "    # Cycle through test samples\n",
    "    sample = test_samples[i % len(test_samples)]\n",
    "    \n",
    "    # Send prediction and get full response\n",
    "    full_response = runtime_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=sample,\n",
    "        ContentType='text/csv'\n",
    "    )\n",
    "    \n",
    "    # Get the variant that served this request\n",
    "    variant_name = full_response['InvokedProductionVariant']\n",
    "    variant_counts.append(variant_name)\n",
    "    \n",
    "    # Progress indicator\n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(f\"  Sent {i + 1}/100 predictions...\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2: Analyze traffic distribution\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"STEP 2: Traffic Distribution Analysis\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Count variant responses\n",
    "variant_distribution = Counter(variant_counts)\n",
    "\n",
    "print(f\"\\nResults from 100 predictions:\")\n",
    "print(f\"  VariantA (Conservative): {variant_distribution.get('VariantA', 0)} requests ({variant_distribution.get('VariantA', 0)}%)\")\n",
    "print(f\"  VariantB (Aggressive):   {variant_distribution.get('VariantB', 0)} requests ({variant_distribution.get('VariantB', 0)}%)\")\n",
    "\n",
    "# Check if distribution is close to expected (80/20)\n",
    "variant_a_pct = variant_distribution.get('VariantA', 0)\n",
    "variant_b_pct = variant_distribution.get('VariantB', 0)\n",
    "\n",
    "print(\"\\nExpected distribution:\")\n",
    "print(\"  VariantA: 80%\")\n",
    "print(\"  VariantB: 20%\")\n",
    "\n",
    "# Tolerance check (allow Â±10% variance due to randomness)\n",
    "if 70 <= variant_a_pct <= 90 and 10 <= variant_b_pct <= 30:\n",
    "    print(\"\\nâœ… Traffic split is working correctly!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Traffic split differs from expected (this can happen with small samples)\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 3: Test targeting specific variants\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"STEP 3: Testing Variant Targeting\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Send requests to specific variants\n",
    "sample = test_samples[0]\n",
    "\n",
    "print(\"\\nSending prediction to VariantA specifically:\")\n",
    "response_a = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=sample,\n",
    "    ContentType='text/csv',\n",
    "    TargetVariant='VariantA'\n",
    ")\n",
    "prediction_a = response_a['Body'].read().decode('utf-8')\n",
    "print(f\"  Variant: {response_a['InvokedProductionVariant']}\")\n",
    "print(f\"  Prediction: {prediction_a}\")\n",
    "\n",
    "print(\"\\nSending prediction to VariantB specifically:\")\n",
    "response_b = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=sample,\n",
    "    ContentType='text/csv',\n",
    "    TargetVariant='VariantB'\n",
    ")\n",
    "prediction_b = response_b['Body'].read().decode('utf-8')\n",
    "print(f\"  Variant: {response_b['InvokedProductionVariant']}\")\n",
    "print(f\"  Prediction: {prediction_b}\")\n",
    "\n",
    "print(\"\\nâœ… Both variants are responding correctly!\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 4: Check endpoint status\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"STEP 4: Endpoint Status Check\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "endpoint_desc = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "print(f\"\\nEndpoint: {endpoint_name}\")\n",
    "print(f\"Status: {endpoint_desc['EndpointStatus']}\")\n",
    "print(f\"\\nProduction Variants:\")\n",
    "\n",
    "for variant in endpoint_desc['ProductionVariants']:\n",
    "    print(f\"\\n  {variant['VariantName']}:\")\n",
    "    print(f\"    Current Weight: {variant['CurrentWeight']}\")\n",
    "    print(f\"    Desired Weight: {variant['DesiredWeight']}\")\n",
    "    print(f\"    Current Instance Count: {variant['CurrentInstanceCount']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 3 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nâœ… Traffic split verified and working!\")\n",
    "print(\"âœ… Both variants tested successfully!\")\n",
    "print(\"\\nReady for Phase 4: Monitoring metrics in CloudWatch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f957f0-2816-4a14-a864-2e2fe3ba32a6",
   "metadata": {},
   "source": [
    "## Monitoring with Cloudwatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7d30e37-c34e-4ae1-b87e-13f01823519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PHASE 4: MONITOR METRICS IN CLOUDWATCH\n",
      "============================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 1: Generating traffic for metrics\n",
      "------------------------------------------------------------\n",
      "\n",
      "Sending 50 more predictions to generate CloudWatch data...\n",
      "  Sent 10/50 predictions...\n",
      "  Sent 20/50 predictions...\n",
      "  Sent 30/50 predictions...\n",
      "  Sent 40/50 predictions...\n",
      "  Sent 50/50 predictions...\n",
      "\n",
      "âœ… Traffic generated\n",
      "Waiting 2 minutes for CloudWatch metrics to populate...\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 2: Retrieving Invocation Metrics\n",
      "------------------------------------------------------------\n",
      "\n",
      "Querying metrics from 20:03 to 20:33 UTC\n",
      "\n",
      "VariantA:\n",
      "  Total Invocations: 129\n",
      "  Invocations by period:\n",
      "    20:23: 87 invocations\n",
      "    20:28: 42 invocations\n",
      "\n",
      "VariantB:\n",
      "  Total Invocations: 23\n",
      "  Invocations by period:\n",
      "    20:23: 15 invocations\n",
      "    20:28: 8 invocations\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 3: Retrieving Latency Metrics\n",
      "------------------------------------------------------------\n",
      "\n",
      "VariantA:\n",
      "  Average Latency: 5252.79 ms\n",
      "  Min Latency: 3780.00 ms\n",
      "  Max Latency: 23164.00 ms\n",
      "\n",
      "VariantB:\n",
      "  Average Latency: 8550.15 ms\n",
      "  Min Latency: 4740.00 ms\n",
      "  Max Latency: 94928.00 ms\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 4: Variant Performance Comparison\n",
      "------------------------------------------------------------\n",
      "\n",
      "Summary:\n",
      "==================================================\n",
      "\n",
      "Total Invocations: 152\n",
      "\n",
      "VariantA (Conservative):\n",
      "  Invocations: 129 (84.9%)\n",
      "\n",
      "VariantB (Aggressive):\n",
      "  Invocations: 23 (15.1%)\n",
      "\n",
      "==================================================\n",
      "\n",
      "ðŸ“Š In a real scenario, you would:\n",
      "  1. Monitor these metrics over days/weeks\n",
      "  2. Compare model accuracy on production data\n",
      "  3. Track business metrics (conversions, etc.)\n",
      "  4. Gradually shift traffic if VariantB performs better\n",
      "  5. Eventually promote winning variant to 100%\n",
      "\n",
      "============================================================\n",
      "PHASE 4 COMPLETE!\n",
      "============================================================\n",
      "\n",
      "âœ… CloudWatch monitoring configured and tested!\n",
      "\n",
      "Next: Phase 5 (Cleanup) to delete resources and avoid charges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_880/252411577.py:46: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  end_time = datetime.utcnow()\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 4: MONITOR METRICS IN CLOUDWATCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "# ============================================================\n",
    "# STEP 1: Generate some traffic for metrics\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"STEP 1: Generating traffic for metrics\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "print(\"\\nSending 50 more predictions to generate CloudWatch data...\")\n",
    "\n",
    "runtime_client = boto3.client('sagemaker-runtime')\n",
    "test_sample = '3,0,22,1,0,7.25,0'\n",
    "\n",
    "for i in range(50):\n",
    "    runtime_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=test_sample,\n",
    "        ContentType='text/csv'\n",
    "    )\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"  Sent {i + 1}/50 predictions...\")\n",
    "\n",
    "print(\"\\nâœ… Traffic generated\")\n",
    "print(\"Waiting 2 minutes for CloudWatch metrics to populate...\")\n",
    "time.sleep(120)  # CloudWatch has a delay\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2: Retrieve invocation metrics\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"STEP 2: Retrieving Invocation Metrics\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Time range: last 30 minutes\n",
    "end_time = datetime.utcnow()\n",
    "start_time = end_time - timedelta(minutes=30)\n",
    "\n",
    "print(f\"\\nQuerying metrics from {start_time.strftime('%H:%M')} to {end_time.strftime('%H:%M')} UTC\")\n",
    "\n",
    "# Get invocation counts for each variant\n",
    "for variant in ['VariantA', 'VariantB']:\n",
    "    print(f\"\\n{variant}:\")\n",
    "    \n",
    "    try:\n",
    "        response = cloudwatch.get_metric_statistics(\n",
    "            Namespace='AWS/SageMaker',\n",
    "            MetricName='Invocations',\n",
    "            Dimensions=[\n",
    "                {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "                {'Name': 'VariantName', 'Value': variant}\n",
    "            ],\n",
    "            StartTime=start_time,\n",
    "            EndTime=end_time,\n",
    "            Period=300,  # 5-minute periods\n",
    "            Statistics=['Sum']\n",
    "        )\n",
    "        \n",
    "        if response['Datapoints']:\n",
    "            datapoints = sorted(response['Datapoints'], key=lambda x: x['Timestamp'])\n",
    "            total_invocations = sum([dp['Sum'] for dp in datapoints])\n",
    "            print(f\"  Total Invocations: {int(total_invocations)}\")\n",
    "            \n",
    "            print(f\"  Invocations by period:\")\n",
    "            for dp in datapoints:\n",
    "                print(f\"    {dp['Timestamp'].strftime('%H:%M')}: {int(dp['Sum'])} invocations\")\n",
    "        else:\n",
    "            print(f\"  No data available yet (metrics may still be processing)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Error retrieving metrics: {e}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 3: Retrieve latency metrics\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"STEP 3: Retrieving Latency Metrics\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for variant in ['VariantA', 'VariantB']:\n",
    "    print(f\"\\n{variant}:\")\n",
    "    \n",
    "    try:\n",
    "        response = cloudwatch.get_metric_statistics(\n",
    "            Namespace='AWS/SageMaker',\n",
    "            MetricName='ModelLatency',\n",
    "            Dimensions=[\n",
    "                {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "                {'Name': 'VariantName', 'Value': variant}\n",
    "            ],\n",
    "            StartTime=start_time,\n",
    "            EndTime=end_time,\n",
    "            Period=300,\n",
    "            Statistics=['Average', 'Maximum', 'Minimum']\n",
    "        )\n",
    "        \n",
    "        if response['Datapoints']:\n",
    "            datapoints = sorted(response['Datapoints'], key=lambda x: x['Timestamp'])\n",
    "            \n",
    "            # Get overall statistics\n",
    "            avg_latencies = [dp['Average'] for dp in datapoints]\n",
    "            overall_avg = sum(avg_latencies) / len(avg_latencies)\n",
    "            \n",
    "            print(f\"  Average Latency: {overall_avg:.2f} ms\")\n",
    "            print(f\"  Min Latency: {min([dp['Minimum'] for dp in datapoints]):.2f} ms\")\n",
    "            print(f\"  Max Latency: {max([dp['Maximum'] for dp in datapoints]):.2f} ms\")\n",
    "        else:\n",
    "            print(f\"  No latency data available yet\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Error retrieving metrics: {e}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 4: Compare variant performance\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"STEP 4: Variant Performance Comparison\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get invocation counts\n",
    "variant_invocations = {}\n",
    "for variant in ['VariantA', 'VariantB']:\n",
    "    try:\n",
    "        response = cloudwatch.get_metric_statistics(\n",
    "            Namespace='AWS/SageMaker',\n",
    "            MetricName='Invocations',\n",
    "            Dimensions=[\n",
    "                {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "                {'Name': 'VariantName', 'Value': variant}\n",
    "            ],\n",
    "            StartTime=start_time,\n",
    "            EndTime=end_time,\n",
    "            Period=1800,  # 30-minute period\n",
    "            Statistics=['Sum']\n",
    "        )\n",
    "        \n",
    "        if response['Datapoints']:\n",
    "            total = sum([dp['Sum'] for dp in response['Datapoints']])\n",
    "            variant_invocations[variant] = int(total)\n",
    "        else:\n",
    "            variant_invocations[variant] = 0\n",
    "    except:\n",
    "        variant_invocations[variant] = 0\n",
    "\n",
    "total_invocations = sum(variant_invocations.values())\n",
    "\n",
    "if total_invocations > 0:\n",
    "    print(f\"\\nTotal Invocations: {total_invocations}\")\n",
    "    print(f\"\\nVariantA (Conservative):\")\n",
    "    print(f\"  Invocations: {variant_invocations['VariantA']} ({variant_invocations['VariantA']/total_invocations*100:.1f}%)\")\n",
    "    print(f\"\\nVariantB (Aggressive):\")\n",
    "    print(f\"  Invocations: {variant_invocations['VariantB']} ({variant_invocations['VariantB']/total_invocations*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"\\nðŸ“Š In a real scenario, you would:\")\n",
    "    print(\"  1. Monitor these metrics over days/weeks\")\n",
    "    print(\"  2. Compare model accuracy on production data\")\n",
    "    print(\"  3. Track business metrics (conversions, etc.)\")\n",
    "    print(\"  4. Gradually shift traffic if VariantB performs better\")\n",
    "    print(\"  5. Eventually promote winning variant to 100%\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Not enough CloudWatch data yet.\")\n",
    "    print(\"   Metrics can take 5-15 minutes to appear.\")\n",
    "    print(\"   In production, you'd monitor over days/weeks.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 4 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nâœ… CloudWatch monitoring configured and tested!\")\n",
    "print(\"\\nNext: Phase 5 (Cleanup) to delete resources and avoid charges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95dd1b3-696d-4eca-a3eb-93b74cfb4bc4",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5595729e-f892-4cec-97d1-9b0da825985c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PHASE 5: CLEANUP\n",
      "============================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 1: Deleting Endpoint\n",
      "------------------------------------------------------------\n",
      "\n",
      "Deleting endpoint: titanic-ab-test-20251117-201747\n",
      "(This stops all billing for instances)\n",
      "âœ… Endpoint 'titanic-ab-test-20251117-201747' deleted successfully\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 2: Deleting Endpoint Configuration\n",
      "------------------------------------------------------------\n",
      "\n",
      "Deleting endpoint config: ab-config-20251117201747\n",
      "âœ… Endpoint config 'ab-config-20251117201747' deleted successfully\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 3: Deleting Models (optional)\n",
      "------------------------------------------------------------\n",
      "\n",
      "Deleting model: model-a-20251117201745\n",
      "âœ… Model 'model-a-20251117201745' deleted\n",
      "\n",
      "Deleting model: model-b-20251117201746\n",
      "âœ… Model 'model-b-20251117201746' deleted\n",
      "\n",
      "============================================================\n",
      "CLEANUP COMPLETE!\n",
      "============================================================\n",
      "\n",
      "âœ… Endpoint deleted (billing stopped)\n",
      "âœ… Endpoint config deleted\n",
      "âœ… Models deleted\n",
      "\n",
      "ðŸ“¦ What's still in S3 (minimal cost):\n",
      "  - Training data: s3://sagemaker-us-east-2-854757836160/titanic-data/\n",
      "  - Model A artifact: s3://sagemaker-us-east-2-854757836160/ab-test/model-a/sagemaker-xgboost-2025-11-17-19-57-50-238/output/model.tar.gz\n",
      "  - Model B artifact: s3://sagemaker-us-east-2-854757836160/ab-test/model-b/sagemaker-xgboost-2025-11-17-20-00-37-185/output/model.tar.gz\n",
      "\n",
      "ðŸ’¡ These S3 files cost ~$0.023/GB/month (pennies)\n",
      "   You can delete them later if needed.\n",
      "\n",
      "============================================================\n",
      "A/B TESTING PROJECT COMPLETE! ðŸŽ‰\n",
      "============================================================\n",
      "\n",
      "ðŸŽ“ What you accomplished:\n",
      "  âœ… Trained two XGBoost models with different hyperparameters\n",
      "  âœ… Deployed multi-variant endpoint with traffic splitting\n",
      "  âœ… Verified 80/20 traffic distribution\n",
      "  âœ… Monitored performance with CloudWatch\n",
      "  âœ… Compared latency between variants\n",
      "  âœ… Cleaned up resources to avoid charges\n",
      "\n",
      "ðŸ“ Key learnings:\n",
      "  â€¢ Multi-variant endpoints enable A/B testing\n",
      "  â€¢ Traffic weights control distribution\n",
      "  â€¢ CloudWatch provides production monitoring\n",
      "  â€¢ Trade-offs exist between accuracy and latency\n",
      "  â€¢ Proper cleanup prevents unexpected AWS bills\n",
      "\n",
      "ðŸš€ Ready for your AWS ML certification exam!\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 5: CLEANUP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "client = boto3.client('sagemaker')\n",
    "\n",
    "# ============================================================\n",
    "# STEP 1: Delete Endpoint\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"STEP 1: Deleting Endpoint\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "print(f\"\\nDeleting endpoint: {endpoint_name}\")\n",
    "print(\"(This stops all billing for instances)\")\n",
    "\n",
    "try:\n",
    "    client.delete_endpoint(EndpointName=endpoint_name)\n",
    "    print(f\"âœ… Endpoint '{endpoint_name}' deleted successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Error deleting endpoint: {e}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2: Delete Endpoint Configuration\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"STEP 2: Deleting Endpoint Configuration\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "print(f\"\\nDeleting endpoint config: {endpoint_config_name}\")\n",
    "\n",
    "try:\n",
    "    client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "    print(f\"âœ… Endpoint config '{endpoint_config_name}' deleted successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Error deleting endpoint config: {e}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 3: Delete Models (Optional - saves clutter)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"STEP 3: Deleting Models (optional)\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for model_name in [model_a_name, model_b_name]:\n",
    "    print(f\"\\nDeleting model: {model_name}\")\n",
    "    try:\n",
    "        client.delete_model(ModelName=model_name)\n",
    "        print(f\"âœ… Model '{model_name}' deleted\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error deleting model: {e}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 4: Summary\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLEANUP COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nâœ… Endpoint deleted (billing stopped)\")\n",
    "print(\"âœ… Endpoint config deleted\")\n",
    "print(\"âœ… Models deleted\")\n",
    "\n",
    "print(\"\\nðŸ“¦ What's still in S3 (minimal cost):\")\n",
    "print(f\"  - Training data: s3://{bucket}/titanic-data/\")\n",
    "print(f\"  - Model A artifact: {xgb_model_a.model_data}\")\n",
    "print(f\"  - Model B artifact: {xgb_model_b.model_data}\")\n",
    "print(\"\\nðŸ’¡ These S3 files cost ~$0.023/GB/month (pennies)\")\n",
    "print(\"   You can delete them later if needed.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"A/B TESTING PROJECT COMPLETE! ðŸŽ‰\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nðŸŽ“ What you accomplished:\")\n",
    "print(\"  âœ… Trained two XGBoost models with different hyperparameters\")\n",
    "print(\"  âœ… Deployed multi-variant endpoint with traffic splitting\")\n",
    "print(\"  âœ… Verified 80/20 traffic distribution\")\n",
    "print(\"  âœ… Monitored performance with CloudWatch\")\n",
    "print(\"  âœ… Compared latency between variants\")\n",
    "print(\"  âœ… Cleaned up resources to avoid charges\")\n",
    "\n",
    "print(\"\\nðŸ“ Key learnings:\")\n",
    "print(\"  â€¢ Multi-variant endpoints enable A/B testing\")\n",
    "print(\"  â€¢ Traffic weights control distribution\")\n",
    "print(\"  â€¢ CloudWatch provides production monitoring\")\n",
    "print(\"  â€¢ Trade-offs exist between accuracy and latency\")\n",
    "print(\"  â€¢ Proper cleanup prevents unexpected AWS bills\")\n",
    "\n",
    "print(\"\\nðŸš€ Ready for your AWS ML certification exam!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef81ee-34ae-4002-9f84-f4339ca9b0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
